Kernel,Ground Truth,LLM Predicted,LLM Rationale,Nsight SM (Compute (SM) Throughput),Nsight DRAM (DRAM Throughput),Nsight Opt (SM Busy),Nsight Opt (Mem Pipes Busy),Nsight Opt (L1/TEX Hit Rate),Nsight Opt (L2 Hit Rate),Nsight Opt (L1/TEX Cache Throughput),Nsight Opt (L2 Cache Throughput),Nsight Opt (Warp Cycles Per Issued Instruction)
high_reg_pressure,MEMORY-BOUND,COMPUTE-BOUND,"The kernel performs a significant amount of floating-point arithmetic within the loop, accumulating values into registers. While it does read and write a single float per thread, the 160 additions within the loop (16 registers * 10 iterations) represent a high number of floating-point operations relative to the memory access. This suggests the kernel is more likely to be limited by the GPU's compute capability than its memory bandwidth. The high register pressure could also lead to register spilling, further impacting performance, but the primary bottleneck is still the arithmetic intensity.",12.4%,92.4%,6.7,12.4,49.4,50.0,18.7,28.1,143.9
naive_matmul,Likely COMPUTE-BOUND,MEMORY-BOUND,"The kernel performs a naive matrix multiplication. For each element C[row, col], it reads N elements from row 'row' of matrix A and N elements from column 'col' of matrix B, and performs N multiply-accumulate operations. Thus, to compute one element of C, the kernel performs 2*N floating-point operations and reads 2*N floats (8*N bytes). The operational intensity is therefore (2*N)/(8*N) = 0.25 FLOPs/Byte. Given the GPU's specifications (9.0 TFLOPs and 192 GB/s), the maximum achievable FLOPs rate if memory-bound is 192 GB/s * 0.25 FLOPs/Byte = 48 TFLOPs. Since the required FLOPs rate to saturate the compute is much higher than what the memory bandwidth can support, the kernel is memory-bound.",98.8%,37.0%,33.0,98.8,87.1,50.0,98.8,22.3,42.3
parallel_reduction,MIXED(Compute/Memory),MEMORY-BOUND,"The kernel performs a parallel reduction. Each thread initially reads two elements from global memory and writes one element to shared memory. Subsequent reduction steps within shared memory involve only shared memory accesses. The dominant cost is reading the initial two elements from global memory. The number of floating point operations is comparable to the number of bytes read from global memory, resulting in a low arithmetic intensity. Given the GPU's compute and memory bandwidth specifications, the kernel is more likely to be limited by memory bandwidth than compute.",73.6%,69.3%,35.8,73.6,0.3,1.5,78.4,16.4,28.4
tiled_transpose,MIXED/OTHER,MEMORY-BOUND,"This kernel performs a tiled matrix transpose. Each thread reads from global memory into shared memory, transposes within shared memory, and then writes back to global memory. The dominant operations are the global memory reads and writes. For each element, there is one read and one write. The arithmetic intensity (FLOPs per byte) is very low. The shared memory is used to facilitate the transpose and mitigate bank conflicts, but the global memory accesses are the bottleneck. Given the GPU's compute and memory bandwidth, the kernel is much more likely to be limited by the memory bandwidth than the compute capability.",71.1%,49.8%,35.8,71.1,34.8,65.2,71.2,27.0,29.9
