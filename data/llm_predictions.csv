kernel,label,rationale
01_saxpy,MEMORY-BOUND,"The kernel performs a single fused multiply-add (FMA) operation per thread, reading one float from `x` and one from `y`, and writing one float to `y`. This results in a low arithmetic intensity (FLOPs/Byte). Specifically, it performs 2 FLOPs (one multiply and one add) and transfers 12 bytes (4 bytes read from x, 4 bytes read from y, and 4 bytes written to y). The arithmetic intensity is therefore 2/12 = 0.167 FLOPs/Byte. Given the GPU's specifications (9 TFLOPs and 192 GB/s), the peak achievable FLOPs if memory-bound is 192 GB/s * 0.167 FLOPs/Byte = 32.064 GFLOPs. The kernel is therefore likely to be limited by the memory bandwidth rather than the compute capability."
02_naive_matmul,MEMORY-BOUND,"The kernel performs a naive matrix multiplication. For each element C[row, col], it reads N elements from row 'row' of matrix A and N elements from column 'col' of matrix B, and performs N multiply-accumulate operations. Thus, to compute one element of C, the kernel performs 2*N floating-point operations and reads 2*N floats (8*N bytes). The operational intensity is therefore (2*N)/(8*N) = 0.25 FLOPs/Byte. Given the GPU's specifications (9.0 TFLOPs and 192 GB/s), the maximum achievable FLOPs rate if memory-bound is 192 GB/s * 0.25 FLOPs/Byte = 48 TFLOPs. Since the required FLOPs rate to saturate the compute is much higher than what the memory bandwidth can support, the kernel is memory-bound."
03_naive_transpose,MEMORY-BOUND,"The kernel performs a naive matrix transpose. For each element, it reads one float from the input and writes one float to the output. This results in a very low arithmetic intensity (FLOPs/Byte). The memory access pattern for the output is uncoalesced (column-major write), further reducing the effective memory bandwidth. The low arithmetic intensity and uncoalesced writes make the kernel heavily memory-bound."
04_tiled_transpose,MEMORY-BOUND,"This kernel performs a tiled matrix transpose. Each thread reads from global memory into shared memory, transposes within shared memory, and then writes back to global memory. The dominant operations are the global memory reads and writes. For each element, there is one read and one write. The arithmetic intensity (FLOPs per byte) is very low. The shared memory is used to facilitate the transpose and mitigate bank conflicts, but the global memory accesses are the bottleneck. Given the GPU's compute and memory bandwidth, the kernel is much more likely to be limited by the memory bandwidth than the compute capability."
05_bank_conflict,LATENCY-BOUND,"The kernel's primary operation involves shared memory access with bank conflicts, exacerbated by the `__syncthreads()` calls. While the code does perform some arithmetic, the dominant factor limiting performance is the serialization of memory accesses due to bank conflicts and the overhead of thread synchronization. The arithmetic intensity is very low, and the global memory is not accessed, so it's not compute or global memory bound. The repeated synchronization points and bank conflicts introduce significant latency, making it latency-bound."
06_strided_global,MEMORY-BOUND,"The kernel performs a simple read and write operation with a stride. Each thread reads one float from global memory, multiplies it by a constant, and writes the result back to global memory. The operational intensity (FLOPs/Byte) is very low (1 FLOP / 8 Bytes = 0.125 FLOPs/Byte). Even with striding, the memory access pattern is still the dominant factor. Given the GPU's compute and memory bandwidth capabilities, the kernel is much more likely to be limited by the memory bandwidth than the compute throughput. The striding could potentially exacerbate the memory bottleneck if it leads to non-coalesced accesses, further reducing effective memory bandwidth."
07_branch_divergence,MEMORY-BOUND,"The kernel reads a float from memory, performs a single floating-point addition or subtraction, and writes the result back to memory. The operational intensity (FLOPs/Byte) is very low (approximately 1 FLOP / 4 Bytes = 0.25 FLOP/Byte). Given the GPU's compute capacity (9 TFLOPs) and memory bandwidth (192 GB/s), the compute bound would require an operational intensity of 9000/192 = 46.875 FLOP/Byte to be fully utilized. Since the kernel's operational intensity is much lower than this, it is memory-bound. The branch divergence, while present, doesn't significantly alter the overall memory access pattern to change the dominant bottleneck."
08_atomic_histogram,LATENCY-BOUND,"The kernel performs an atomicAdd operation to update a histogram. Atomic operations, especially when targeting a small number of bins, introduce significant serialization and contention. This contention forces threads to wait, making the kernel latency-bound. While memory access is involved, the primary bottleneck is the latency associated with resolving conflicts and ensuring atomicity during the updates to the histogram bins. The compute intensity is very low, and while memory bandwidth is used, the serialization due to atomics dominates the performance."
09_high_reg_pressure,COMPUTE-BOUND,"The kernel performs a significant amount of floating-point arithmetic within the loop, accumulating values into registers. While it does read and write a single float per thread, the 160 additions within the loop (16 registers * 10 iterations) represent a high number of floating-point operations relative to the memory access. This suggests the kernel is more likely to be limited by the GPU's compute capability than its memory bandwidth. The high register pressure could also lead to register spilling, further impacting performance, but the primary bottleneck is still the arithmetic intensity."
10_parallel_reduction,MEMORY-BOUND,"The kernel performs a parallel reduction. Each thread initially reads two elements from global memory and writes one element to shared memory. Subsequent reduction steps within shared memory involve only shared memory accesses. The dominant cost is reading the initial two elements from global memory. The number of floating point operations is comparable to the number of bytes read from global memory, resulting in a low arithmetic intensity. Given the GPU's compute and memory bandwidth specifications, the kernel is more likely to be limited by memory bandwidth than compute."
11_tiled_matmul,COMPUTE-BOUND,"This kernel performs a tiled matrix multiplication. Each thread computes a partial dot product of size TILE_WIDTH (32 in this case) in the inner loop. The data is loaded into shared memory, which significantly reduces the memory bandwidth requirements compared to a naive matrix multiplication. The dominant operation is the floating-point multiplication and addition within the inner loop. The operational intensity (FLOPs/Byte) is high due to the reuse of data in shared memory. Therefore, the kernel is more likely to be limited by the GPU's compute capability rather than memory bandwidth or latency."
